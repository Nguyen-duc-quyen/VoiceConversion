{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"make_metadata","provenance":[],"authorship_tag":"ABX9TyPcHagSJyEZqY4xzbpL1GKj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoI9E-R4Pnpw","executionInfo":{"status":"ok","timestamp":1642020845738,"user_tz":-420,"elapsed":27976,"user":{"displayName":"Quyền Nguyễn Đức","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01047503131149573179"}},"outputId":"1ad65e56-6c4d-424e-94fb-567ef6eb346b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pSCakCzP8Q3","executionInfo":{"status":"ok","timestamp":1642020849512,"user_tz":-420,"elapsed":551,"user":{"displayName":"Quyền Nguyễn Đức","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01047503131149573179"}},"outputId":"d3291b62-5531-49f6-aeab-3806267589d6"},"source":["%cd /content/gdrive/MyDrive/Voice_coversion"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Voice_coversion\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yAuYZznQksJ","executionInfo":{"status":"ok","timestamp":1642020857717,"user_tz":-420,"elapsed":6396,"user":{"displayName":"Quyền Nguyễn Đức","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01047503131149573179"}},"outputId":"8290ff2a-7acc-4a9b-a59f-0d5ebce9812d"},"source":["import torch\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"id":"bJA5XM-_QsqT","executionInfo":{"status":"ok","timestamp":1642020859928,"user_tz":-420,"elapsed":349,"user":{"displayName":"Quyền Nguyễn Đức","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01047503131149573179"}}},"source":["import os\n","import pickle\n","from speaker_encoder import D_VECTOR\n","from collections import OrderedDict\n","import numpy as np\n","import torch"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#check the data\n","rootDir = './spmel_16khz'\n","dirName, subdirList, _ = next(os.walk(rootDir))\n","print('Found directory: %s' % dirName)\n","\n","drop_point = 30\n","subdirList = sorted(subdirList)[:drop_point]\n","\n","print(subdirList)\n","print(len(subdirList))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WNiBtfXYYwD","executionInfo":{"status":"ok","timestamp":1642020863215,"user_tz":-420,"elapsed":326,"user":{"displayName":"Quyền Nguyễn Đức","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01047503131149573179"}},"outputId":"6bcb9cee-7da4-4df2-b69f-955f53543f09"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found directory: ./spmel_16khz\n","['p225', 'p226', 'p227', 'p228', 'p229', 'p230', 'p231', 'p232', 'p233', 'p234', 'p236', 'p237', 'p238', 'p239', 'p240', 'p241', 'p243', 'p244', 'p245', 'p246', 'p247', 'p248', 'p249', 'p250', 'p251', 'p252', 'p253', 'p254', 'p255', 'p256']\n","30\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPUgvr4mPeUw","executionInfo":{"status":"ok","timestamp":1642021585832,"user_tz":-420,"elapsed":183474,"user":{"displayName":"Quyền Nguyễn Đức","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01047503131149573179"}},"outputId":"95924be5-4600-4af3-851b-a406d2623db0"},"source":["C = D_VECTOR(dim_input=80, dim_cell=768, dim_emb=256).eval().cuda()\n","c_checkpoint = torch.load('checkpoints/Speaker/3000000-BL.ckpt')\n","new_state_dict = OrderedDict()\n","for key, val in c_checkpoint['model_b'].items():\n","    new_key = key[7:]\n","    new_state_dict[new_key] = val\n","C.load_state_dict(new_state_dict)\n","num_uttrs = 10\n","len_crop = 128\n","\n","speakers = []\n","print(\"Number of speakers: {}\".format(len(subdirList)))\n","for speaker in sorted(subdirList):\n","    utterances = []\n","    utterances.append(speaker)\n","    _, _, fileList = next(os.walk(os.path.join(dirName,speaker)))\n","    print('Processing speaker:{}, num utterances: {}'.format(speaker, len(fileList)))\n","    # make speaker embedding\n","    assert len(fileList) >= num_uttrs\n","    idx_uttrs = np.random.choice(len(fileList), size=num_uttrs, replace=False)\n","    embs = []\n","    for i in range(num_uttrs):\n","        tmp = np.load(os.path.join(dirName, speaker, fileList[idx_uttrs[i]]))\n","        candidates = np.delete(np.arange(len(fileList)), idx_uttrs)\n","        # choose another utterance if the current one is too short\n","        while tmp.shape[0] < len_crop:\n","            idx_alt = np.random.choice(candidates)\n","            tmp = np.load(os.path.join(dirName, speaker, fileList[idx_alt]))\n","            candidates = np.delete(candidates, np.argwhere(candidates==idx_alt))\n","        left = np.random.randint(0, tmp.shape[0]-len_crop)\n","        melsp = torch.from_numpy(tmp[np.newaxis, left:left+len_crop, :]).cuda()\n","        emb = C(melsp)\n","        embs.append(emb.detach().squeeze().cpu().numpy())     \n","    utterances.append(np.mean(embs, axis=0))\n","    \n","    # create file list\n","    for fileName in sorted(fileList):\n","        utterances.append(os.path.join(speaker,fileName))\n","    speakers.append(utterances)\n","    \n","with open(os.path.join(rootDir, 'train.pkl'), 'wb') as handle:\n","    pickle.dump(speakers, handle)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of speakers: 30\n","Processing speaker:p225, num utterances: 462\n","Processing speaker:p226, num utterances: 712\n","Processing speaker:p227, num utterances: 778\n","Processing speaker:p228, num utterances: 732\n","Processing speaker:p229, num utterances: 758\n","Processing speaker:p230, num utterances: 794\n","Processing speaker:p231, num utterances: 912\n","Processing speaker:p232, num utterances: 822\n","Processing speaker:p233, num utterances: 744\n","Processing speaker:p234, num utterances: 714\n","Processing speaker:p236, num utterances: 984\n","Processing speaker:p237, num utterances: 678\n","Processing speaker:p238, num utterances: 908\n","Processing speaker:p239, num utterances: 1004\n","Processing speaker:p240, num utterances: 754\n","Processing speaker:p241, num utterances: 706\n","Processing speaker:p243, num utterances: 786\n","Processing speaker:p244, num utterances: 840\n","Processing speaker:p245, num utterances: 708\n","Processing speaker:p246, num utterances: 716\n","Processing speaker:p247, num utterances: 950\n","Processing speaker:p248, num utterances: 752\n","Processing speaker:p249, num utterances: 670\n","Processing speaker:p250, num utterances: 962\n","Processing speaker:p251, num utterances: 728\n","Processing speaker:p252, num utterances: 790\n","Processing speaker:p253, num utterances: 750\n","Processing speaker:p254, num utterances: 792\n","Processing speaker:p255, num utterances: 758\n","Processing speaker:p256, num utterances: 638\n"]}]}]}